{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Price Prediction - Baseline Model\n",
    "## CPSC 4310 - Milestone 2\n",
    "\n",
    "**Student:** Chloe Lee  \n",
    "**Date:** February 2025  \n",
    "**Goal:** Build baseline Linear Regression model to predict housing price changes\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives:\n",
    "1. Load feature-engineered dataset\n",
    "2. Select target variable (monthly price % change)\n",
    "3. Create train/test split (time-based)\n",
    "4. Build Linear Regression baseline\n",
    "5. Evaluate performance (RMSE, MAE, R², MAPE)\n",
    "6. Visualize Actual vs Predicted\n",
    "7. Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature-engineered dataset\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Update path if your CSV is elsewhere\n",
    "df = pd.read_csv('output\\housing_data_with_features.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(f\"✓ Data loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
    "print(f\"  Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"  Cities: {df['City'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "print(\"\\nData Preview:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nColumn List:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Target Variable Selection\n",
    "\n",
    "We'll predict **Month-over-Month % Change** in housing prices.\n",
    "\n",
    "**Why MoM Change instead of Index?**\n",
    "- Index values vary widely by city (Vancouver 100-350, etc.)\n",
    "- % Change is comparable across cities\n",
    "- More meaningful: \"Prices will increase 2% next month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if target variable exists\n",
    "print(\"Target Variable: Index_MoM_Change\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'Index_MoM_Change' in df.columns:\n",
    "    print(\"✓ Index_MoM_Change found in dataset\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(df['Index_MoM_Change'].describe())\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(df['Index_MoM_Change'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Distribution of MoM Price Change', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('MoM Change (%)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].axvline(0, color='red', linestyle='--', alpha=0.5, label='0% change')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Time series\n",
    "    for city in df['City'].unique()[:3]:  # Show 3 cities for clarity\n",
    "        city_data = df[df['City'] == city].sort_values('Date')\n",
    "        axes[1].plot(city_data['Date'], city_data['Index_MoM_Change'], \n",
    "                    label=city, alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    axes[1].set_title('MoM Change Over Time (Sample Cities)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('MoM Change (%)')\n",
    "    axes[1].axhline(0, color='black', linestyle='-', alpha=0.3, linewidth=0.5)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Index_MoM_Change not found! Need to create it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Feature Selection\n",
    "\n",
    "Select features that will be used to predict the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    # Lag features (past prices)\n",
    "    'Index_Lag1',\n",
    "    'Index_Lag3',\n",
    "    'Index_Lag12',\n",
    "    \n",
    "    # Interest rates\n",
    "    'Mortgage_1Y',\n",
    "    'Mortgage_3Y',\n",
    "    'Mortgage_5Y',\n",
    "    'Prime_Rate',\n",
    "    \n",
    "    # Change features\n",
    "    'Index_YoY_Change',\n",
    "    'Mortgage_5Y_Change',\n",
    "    \n",
    "    # Rolling averages\n",
    "    'Index_MA3',\n",
    "    'Index_MA12',\n",
    "    \n",
    "    # Time features\n",
    "    'Month',\n",
    "    'Quarter',\n",
    "    \n",
    "    # Derived features\n",
    "    'Price_Above_MA3',\n",
    "    'MA3_MA12_Diff'\n",
    "]\n",
    "\n",
    "target_col = 'Index_MoM_Change'\n",
    "\n",
    "print(f\"Features selected: {len(feature_cols)}\")\n",
    "print(\"\\nFeature list:\")\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2}. {feat}\")\n",
    "\n",
    "print(f\"\\nTarget: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in features and target\n",
    "print(\"Missing Values Check:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_features = df[feature_cols].isnull().sum()\n",
    "missing_features = missing_features[missing_features > 0]\n",
    "\n",
    "if len(missing_features) > 0:\n",
    "    print(\"\\nFeatures with missing values:\")\n",
    "    for feat, count in missing_features.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {feat:25} : {count:4} ({pct:5.1f}%)\")\n",
    "else:\n",
    "    print(\"✓ No missing values in features\")\n",
    "\n",
    "target_missing = df[target_col].isnull().sum()\n",
    "print(f\"\\nTarget ({target_col}): {target_missing} missing ({target_missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Remove rows with NaN\n",
    "print(\"\\nRemoving rows with missing values...\")\n",
    "df_clean = df[feature_cols + [target_col, 'Date', 'City', 'Year']].dropna()\n",
    "\n",
    "print(f\"Before: {len(df)} rows\")\n",
    "print(f\"After:  {len(df_clean)} rows\")\n",
    "print(f\"Removed: {len(df) - len(df_clean)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Train/Test Split (Time-Based)\n",
    "\n",
    "**CRITICAL:** For time-series data, we MUST use time-based split!\n",
    "\n",
    "- **Train:** 2005-2023 (earlier data)\n",
    "- **Test:** 2024-2025 (recent data)\n",
    "\n",
    "**Why?** We want to predict the future, not shuffle past and future together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "print(\"Creating Train/Test Split...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define split year\n",
    "SPLIT_YEAR = 2024\n",
    "\n",
    "# Create masks\n",
    "train_mask = df_clean['Year'] < SPLIT_YEAR\n",
    "test_mask = df_clean['Year'] >= SPLIT_YEAR\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_clean.loc[train_mask, feature_cols]\n",
    "y_train = df_clean.loc[train_mask, target_col]\n",
    "\n",
    "X_test = df_clean.loc[test_mask, feature_cols]\n",
    "y_test = df_clean.loc[test_mask, target_col]\n",
    "\n",
    "# Print split info\n",
    "print(f\"Split year: {SPLIT_YEAR}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Date range: {df_clean.loc[train_mask, 'Date'].min()} to {df_clean.loc[train_mask, 'Date'].max()}\")\n",
    "print(f\"  Rows: {len(X_train)}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Date range: {df_clean.loc[test_mask, 'Date'].min()} to {df_clean.loc[test_mask, 'Date'].max()}\")\n",
    "print(f\"  Rows: {len(X_test)}\")\n",
    "print(f\"  Features: {X_test.shape[1]}\")\n",
    "\n",
    "print(f\"\\nSplit ratio: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}% train, \"\n",
    "      f\"{len(X_test)/(len(X_train)+len(X_test))*100:.1f}% test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Baseline Model - Linear Regression\n",
    "\n",
    "Linear Regression is our baseline model. It assumes a linear relationship between features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression\n",
    "print(\"Training Linear Regression Model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✓ Model trained successfully!\")\n",
    "print(f\"\\nModel coefficients: {len(lr_model.coef_)}\")\n",
    "print(f\"Intercept: {lr_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"✓ Predictions generated\")\n",
    "print(f\"  Train predictions: {len(y_train_pred)}\")\n",
    "print(f\"  Test predictions: {len(y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Model Evaluation\n",
    "\n",
    "We evaluate using 4 metrics:\n",
    "- **RMSE** (Root Mean Squared Error) - lower is better\n",
    "- **MAE** (Mean Absolute Error) - lower is better\n",
    "- **R²** (R-squared) - higher is better (0-1 scale)\n",
    "- **MAPE** (Mean Absolute Percentage Error) - lower is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Calculate regression metrics\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    # Handle division by zero\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    print(f\"{dataset_name} Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training\")\n",
    "print()\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if test_metrics['R2'] > 0.70:\n",
    "    print(\"✓ GOOD! R² > 0.70 - Model explains >70% of variance\")\n",
    "elif test_metrics['R2'] > 0.50:\n",
    "    print(\"⚠ OK - R² > 0.50 but room for improvement\")\n",
    "else:\n",
    "    print(\"✗ POOR - R² < 0.50 - Model needs improvement\")\n",
    "\n",
    "if test_metrics['MAPE'] < 8:\n",
    "    print(\"✓ EXCELLENT! MAPE < 8% - Predictions very accurate\")\n",
    "elif test_metrics['MAPE'] < 15:\n",
    "    print(\"⚠ ACCEPTABLE - MAPE < 15% - Decent predictions\")\n",
    "else:\n",
    "    print(\"✗ HIGH ERROR - MAPE > 15% - Predictions not reliable\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_metrics['R2'] - test_metrics['R2'] > 0.15:\n",
    "    print(\"\\n⚠ WARNING: Possible overfitting detected!\")\n",
    "    print(f\"   Train R²: {train_metrics['R2']:.3f} vs Test R²: {test_metrics['R2']:.3f}\")\n",
    "else:\n",
    "    print(\"\\n✓ Good generalization - similar train/test performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 7: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Actual vs Predicted Scatter Plot\n",
    "print(\"Creating Actual vs Predicted visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Training set\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.5, s=20)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual MoM Change (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted MoM Change (%)', fontsize=12)\n",
    "axes[0].set_title(f'Training Set (R² = {train_metrics[\"R2\"]:.3f})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "axes[1].scatter(y_test, y_test_pred, alpha=0.5, s=20, color='orange')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual MoM Change (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted MoM Change (%)', fontsize=12)\n",
    "axes[1].set_title(f'Test Set (R² = {test_metrics[\"R2\"]:.3f})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Linear Regression: Actual vs Predicted', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Residual Plot\n",
    "print(\"Creating residual plot...\")\n",
    "\n",
    "residuals_train = y_train - y_train_pred\n",
    "residuals_test = y_test - y_test_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Training residuals\n",
    "axes[0].scatter(y_train_pred, residuals_train, alpha=0.5, s=20)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0].set_xlabel('Predicted MoM Change (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals', fontsize=12)\n",
    "axes[0].set_title('Training Set Residuals', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Test residuals\n",
    "axes[1].scatter(y_test_pred, residuals_test, alpha=0.5, s=20, color='orange')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted MoM Change (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Test Set Residuals', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Residual Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Residual plot complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Feature Importance (Coefficients)\n",
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': lr_model.coef_\n",
    "})\n",
    "\n",
    "# Sort by absolute value\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=True)\n",
    "\n",
    "# Plot top 10 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['Feature'].tail(10), \n",
    "         feature_importance['Coefficient'].tail(10))\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Top 10 Feature Coefficients (Linear Regression)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(\"=\" * 60)\n",
    "top_features = feature_importance.sort_values('Abs_Coefficient', ascending=False).head(10)\n",
    "for i, row in enumerate(top_features.itertuples(), 1):\n",
    "    print(f\"{i:2}. {row.Feature:25} : {row.Coefficient:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 8: Results Interpretation\n",
    "\n",
    "Let's interpret what our model tells us about housing price predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MODEL INTERPRETATION & INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE:\")\n",
    "print(f\"   Test R² = {test_metrics['R2']:.3f}\")\n",
    "print(f\"   → Model explains {test_metrics['R2']*100:.1f}% of price variance\")\n",
    "print(f\"\\n   Test MAPE = {test_metrics['MAPE']:.2f}%\")\n",
    "print(f\"   → Average prediction error is {test_metrics['MAPE']:.1f}%\")\n",
    "\n",
    "print(\"\\n2. KEY FINDINGS:\")\n",
    "\n",
    "# Find most important features\n",
    "top_3_features = feature_importance.sort_values('Abs_Coefficient', ascending=False).head(3)\n",
    "print(\"\\n   Most Influential Features:\")\n",
    "for i, row in enumerate(top_3_features.itertuples(), 1):\n",
    "    direction = \"increases\" if row.Coefficient > 0 else \"decreases\"\n",
    "    print(f\"   {i}. {row.Feature}\")\n",
    "    print(f\"      Coefficient: {row.Coefficient:.4f}\")\n",
    "    print(f\"      → When this {direction}, predicted price change {direction}\")\n",
    "\n",
    "print(\"\\n3. MODEL STRENGTHS:\")\n",
    "if test_metrics['R2'] > 0.70:\n",
    "    print(\"   ✓ Strong predictive power (R² > 0.70)\")\n",
    "if test_metrics['MAPE'] < 10:\n",
    "    print(\"   ✓ Low prediction error (MAPE < 10%)\")\n",
    "if abs(train_metrics['R2'] - test_metrics['R2']) < 0.10:\n",
    "    print(\"   ✓ Good generalization (no overfitting)\")\n",
    "\n",
    "print(\"\\n4. MODEL LIMITATIONS:\")\n",
    "print(\"   ⚠ Linear assumption may be too simple\")\n",
    "print(\"   ⚠ Doesn't capture complex non-linear patterns\")\n",
    "print(\"   ⚠ Treats all cities equally (no city-specific effects)\")\n",
    "\n",
    "print(\"\\n5. NEXT STEPS:\")\n",
    "print(\"   → Try Random Forest (captures non-linearity)\")\n",
    "print(\"   → Try XGBoost (best performance expected)\")\n",
    "print(\"   → Add city-specific features or separate models\")\n",
    "print(\"   → Feature selection to reduce complexity\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 9: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model performance\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression'],\n",
    "    'Train_RMSE': [train_metrics['RMSE']],\n",
    "    'Test_RMSE': [test_metrics['RMSE']],\n",
    "    'Train_MAE': [train_metrics['MAE']],\n",
    "    'Test_MAE': [test_metrics['MAE']],\n",
    "    'Train_R2': [train_metrics['R2']],\n",
    "    'Test_R2': [test_metrics['R2']],\n",
    "    'Train_MAPE': [train_metrics['MAPE']],\n",
    "    'Test_MAPE': [test_metrics['MAPE']]\n",
    "})\n",
    "\n",
    "results_df.to_csv('baseline_model_performance.csv', index=False)\n",
    "print(\"✓ Model performance saved to: baseline_model_performance.csv\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance[['Feature', 'Coefficient']].to_csv('baseline_feature_importance.csv', index=False)\n",
    "print(\"✓ Feature importance saved to: baseline_feature_importance.csv\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_test_pred,\n",
    "    'Error': y_test.values - y_test_pred,\n",
    "    'Abs_Error': np.abs(y_test.values - y_test_pred)\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('baseline_predictions.csv', index=False)\n",
    "print(\"✓ Predictions saved to: baseline_predictions.csv\")\n",
    "\n",
    "print(\"\\n✓ All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## What We Accomplished:\n",
    "✅ Loaded feature-engineered dataset  \n",
    "✅ Selected target variable (MoM % change)  \n",
    "✅ Created time-based train/test split  \n",
    "✅ Built Linear Regression baseline model  \n",
    "✅ Evaluated with RMSE, MAE, R², MAPE  \n",
    "✅ Created visualizations (Actual vs Predicted, Residuals, Feature Importance)  \n",
    "✅ Interpreted results and identified next steps  \n",
    "\n",
    "## Results:\n",
    "- **Test R²:** Check output above\n",
    "- **Test MAPE:** Check output above\n",
    "- **Status:** Baseline established ✓\n",
    "\n",
    "## Next Steps:\n",
    "1. Build Random Forest model\n",
    "2. Build XGBoost model\n",
    "3. Compare all models\n",
    "4. Select best model for deployment\n",
    "5. Create final predictions for Vergil's dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
