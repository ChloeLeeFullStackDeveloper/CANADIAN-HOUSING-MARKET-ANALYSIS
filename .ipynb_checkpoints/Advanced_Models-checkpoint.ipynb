{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Price Prediction - Advanced Models\n",
    "## CPSC 4310 - Milestone 3\n",
    "\n",
    "**Student:** Chloe Lee  \n",
    "**Date:** February 2025  \n",
    "**Goal:** Build advanced models (Random Forest & XGBoost) to improve predictions\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives:\n",
    "1. Load baseline model results for comparison\n",
    "2. Build Random Forest model\n",
    "3. Build XGBoost model\n",
    "4. Compare all three models\n",
    "5. Analyze feature importance\n",
    "6. Generate final predictions for dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/chloelee/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: seaborn in /Users/chloelee/anaconda3/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/chloelee/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: xgboost in /Users/chloelee/anaconda3/lib/python3.11/site-packages (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/chloelee/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Run the line above if you get import errors!\n"
     ]
    }
   ],
   "source": [
    "# Install if needed (uncomment and run once):\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn xgboost\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib seaborn scikit-learn xgboost\n",
    "print(\"Run the line above if you get import errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing_data_with_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousing_data_with_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Data loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing_data_with_features.csv'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('output/housing_data_with_features.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(f\"‚úì Data loaded: {len(df)} rows, {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target (same as baseline)\n",
    "feature_cols = [\n",
    "    'Index_Lag1', 'Index_Lag3', 'Index_Lag12',\n",
    "    'Mortgage_1Y', 'Mortgage_3Y', 'Mortgage_5Y', 'Prime_Rate',\n",
    "    'Index_YoY_Change', 'Mortgage_5Y_Change',\n",
    "    'Index_MA3', 'Index_MA12',\n",
    "    'Month', 'Quarter',\n",
    "    'Price_Above_MA3', 'MA3_MA12_Diff'\n",
    "]\n",
    "\n",
    "target_col = 'Index_MoM_Change'\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (same as baseline)\n",
    "print(\"Preparing data...\")\n",
    "\n",
    "df_clean = df[feature_cols + [target_col, 'Date', 'City', 'Year']].dropna()\n",
    "\n",
    "SPLIT_YEAR = 2024\n",
    "train_mask = df_clean['Year'] < SPLIT_YEAR\n",
    "test_mask = df_clean['Year'] >= SPLIT_YEAR\n",
    "\n",
    "X_train = df_clean.loc[train_mask, feature_cols]\n",
    "y_train = df_clean.loc[train_mask, target_col]\n",
    "X_test = df_clean.loc[test_mask, feature_cols]\n",
    "y_test = df_clean.loc[test_mask, target_col]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Load Baseline Results\n",
    "\n",
    "Load the baseline model results to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load baseline results (if available)\n",
    "try:\n",
    "    baseline_results = pd.read_csv('baseline_model_performance.csv')\n",
    "    print(\"Baseline Model Performance:\")\n",
    "    print(\"=\"*60)\n",
    "    display(baseline_results)\n",
    "    \n",
    "    baseline_test_r2 = baseline_results['Test_R2'].values[0]\n",
    "    baseline_test_mape = baseline_results['Test_MAPE'].values[0]\n",
    "    \n",
    "    print(f\"\\n‚úì Baseline to beat:\")\n",
    "    print(f\"  R¬≤ = {baseline_test_r2:.4f}\")\n",
    "    print(f\"  MAPE = {baseline_test_mape:.2f}%\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö† Baseline results not found. We'll still build advanced models!\")\n",
    "    baseline_test_r2 = None\n",
    "    baseline_test_mape = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Random Forest Model\n",
    "\n",
    "**Why Random Forest?**\n",
    "- Handles non-linear relationships (Linear Regression can't)\n",
    "- Less prone to overfitting than single decision tree\n",
    "- Provides feature importance\n",
    "- No need to scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING RANDOM FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=15,          # Maximum depth of each tree\n",
    "    min_samples_split=5,   # Minimum samples to split a node\n",
    "    min_samples_leaf=2,    # Minimum samples in a leaf\n",
    "    random_state=42,       # For reproducibility\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    verbose=1              # Show progress\n",
    ")\n",
    "\n",
    "print(\"\\nModel parameters:\")\n",
    "print(f\"  Trees: {rf_model.n_estimators}\")\n",
    "print(f\"  Max depth: {rf_model.max_depth}\")\n",
    "print(f\"  Min samples split: {rf_model.min_samples_split}\")\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "print(\"‚úì Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "def calculate_metrics(y_true, y_pred, model_name=\"\"):\n",
    "    \"\"\"Calculate all metrics\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'Model': model_name, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_train_metrics = calculate_metrics(y_train, rf_train_pred, \"RF Training\")\n",
    "print()\n",
    "rf_test_metrics = calculate_metrics(y_test, rf_test_pred, \"RF Test\")\n",
    "\n",
    "# Compare with baseline\n",
    "if baseline_test_r2 is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON WITH BASELINE\")\n",
    "    print(\"=\"*60)\n",
    "    r2_improvement = ((rf_test_metrics['R2'] - baseline_test_r2) / baseline_test_r2) * 100\n",
    "    mape_improvement = ((baseline_test_mape - rf_test_metrics['MAPE']) / baseline_test_mape) * 100\n",
    "    \n",
    "    print(f\"R¬≤ improvement: {r2_improvement:+.1f}%\")\n",
    "    print(f\"MAPE improvement: {mape_improvement:+.1f}%\")\n",
    "    \n",
    "    if rf_test_metrics['R2'] > baseline_test_r2:\n",
    "        print(\"\\n‚úì Random Forest BEATS baseline!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö† Random Forest did not beat baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: XGBoost Model\n",
    "\n",
    "**Why XGBoost?**\n",
    "- Usually best performance for tabular data\n",
    "- Handles complex patterns\n",
    "- Built-in regularization prevents overfitting\n",
    "- Very fast training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING XGBOOST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,       # Number of boosting rounds\n",
    "    max_depth=6,            # Maximum depth of trees\n",
    "    learning_rate=0.1,      # Step size for updates\n",
    "    subsample=0.8,          # Fraction of samples for each tree\n",
    "    colsample_bytree=0.8,   # Fraction of features for each tree\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel parameters:\")\n",
    "print(f\"  Estimators: {xgb_model.n_estimators}\")\n",
    "print(f\"  Max depth: {xgb_model.max_depth}\")\n",
    "print(f\"  Learning rate: {xgb_model.learning_rate}\")\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_test_pred = xgb_model.predict(X_test)\n",
    "print(\"‚úì Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "print(\"=\"*60)\n",
    "print(\"XGBOOST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_train_metrics = calculate_metrics(y_train, xgb_train_pred, \"XGB Training\")\n",
    "print()\n",
    "xgb_test_metrics = calculate_metrics(y_test, xgb_test_pred, \"XGB Test\")\n",
    "\n",
    "# Compare with baseline\n",
    "if baseline_test_r2 is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON WITH BASELINE\")\n",
    "    print(\"=\"*60)\n",
    "    r2_improvement = ((xgb_test_metrics['R2'] - baseline_test_r2) / baseline_test_r2) * 100\n",
    "    mape_improvement = ((baseline_test_mape - xgb_test_metrics['MAPE']) / baseline_test_mape) * 100\n",
    "    \n",
    "    print(f\"R¬≤ improvement: {r2_improvement:+.1f}%\")\n",
    "    print(f\"MAPE improvement: {mape_improvement:+.1f}%\")\n",
    "    \n",
    "    if xgb_test_metrics['R2'] > baseline_test_r2:\n",
    "        print(\"\\n‚úì XGBoost BEATS baseline!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö† XGBoost did not beat baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "# Add baseline if available\n",
    "if baseline_test_r2 is not None:\n",
    "    comparison_data.append({\n",
    "        'Model': 'Linear Regression',\n",
    "        'Test_RMSE': baseline_results['Test_RMSE'].values[0],\n",
    "        'Test_MAE': baseline_results['Test_MAE'].values[0],\n",
    "        'Test_R2': baseline_results['Test_R2'].values[0],\n",
    "        'Test_MAPE': baseline_results['Test_MAPE'].values[0]\n",
    "    })\n",
    "\n",
    "# Add Random Forest\n",
    "comparison_data.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Test_RMSE': rf_test_metrics['RMSE'],\n",
    "    'Test_MAE': rf_test_metrics['MAE'],\n",
    "    'Test_R2': rf_test_metrics['R2'],\n",
    "    'Test_MAPE': rf_test_metrics['MAPE']\n",
    "})\n",
    "\n",
    "# Add XGBoost\n",
    "comparison_data.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Test_RMSE': xgb_test_metrics['RMSE'],\n",
    "    'Test_MAE': xgb_test_metrics['MAE'],\n",
    "    'Test_R2': xgb_test_metrics['R2'],\n",
    "    'Test_MAPE': xgb_test_metrics['MAPE']\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['Test_R2'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "best_r2 = comparison_df.loc[best_model_idx, 'Test_R2']\n",
    "best_mape = comparison_df.loc[best_model_idx, 'Test_MAPE']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Test R¬≤: {best_r2:.4f}\")\n",
    "print(f\"Test MAPE: {best_mape:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Test_RMSE', 'Test_MAE', 'Test_R2', 'Test_MAPE']\n",
    "titles = ['RMSE (lower is better)', 'MAE (lower is better)', \n",
    "          'R¬≤ (higher is better)', 'MAPE % (lower is better)']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    \n",
    "    values = comparison_df[metric].values\n",
    "    models = comparison_df['Model'].values\n",
    "    \n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71'][:len(models)]\n",
    "    bars = ax.bar(models, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Highlight best\n",
    "    if metric == 'Test_R2':\n",
    "        best_idx = np.argmax(values)\n",
    "    else:\n",
    "        best_idx = np.argmin(values)\n",
    "    bars[best_idx].set_color('#f39c12')\n",
    "    bars[best_idx].set_edgecolor('black')\n",
    "    bars[best_idx].set_linewidth(3)\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric.replace('Test_', ''))\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    # Add value labels\n",
    "    for j, (bar, val) in enumerate(zip(bars, values)):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, val, \n",
    "               f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "print(\"Random Forest Feature Importance:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "display(rf_importance.head(10))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(rf_importance['Feature'].head(10), rf_importance['Importance'].head(10), \n",
    "         color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Random Forest: Top 10 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Feature Importance\n",
    "print(\"\\nXGBoost Feature Importance:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "display(xgb_importance.head(10))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(xgb_importance['Feature'].head(10), xgb_importance['Importance'].head(10), \n",
    "         color='#2ecc71', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('XGBoost: Top 10 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 7: Actual vs Predicted Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models - Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 3 if baseline_test_r2 is not None else 2, \n",
    "                         figsize=(18 if baseline_test_r2 is not None else 12, 5))\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# Baseline (if available)\n",
    "if baseline_test_r2 is not None:\n",
    "    try:\n",
    "        baseline_pred = pd.read_csv('baseline_predictions.csv')\n",
    "        axes[plot_idx].scatter(baseline_pred['Actual'], baseline_pred['Predicted'], \n",
    "                              alpha=0.5, s=20, color='#3498db')\n",
    "        axes[plot_idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                           'r--', lw=2)\n",
    "        axes[plot_idx].set_xlabel('Actual', fontsize=12)\n",
    "        axes[plot_idx].set_ylabel('Predicted', fontsize=12)\n",
    "        axes[plot_idx].set_title(f'Linear Regression (R¬≤={baseline_test_r2:.3f})', \n",
    "                                fontsize=12, fontweight='bold')\n",
    "        axes[plot_idx].grid(alpha=0.3)\n",
    "        plot_idx += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Random Forest\n",
    "axes[plot_idx].scatter(y_test, rf_test_pred, alpha=0.5, s=20, color='#e74c3c')\n",
    "axes[plot_idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                   'r--', lw=2)\n",
    "axes[plot_idx].set_xlabel('Actual', fontsize=12)\n",
    "axes[plot_idx].set_ylabel('Predicted', fontsize=12)\n",
    "axes[plot_idx].set_title(f'Random Forest (R¬≤={rf_test_metrics[\"R2\"]:.3f})', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "axes[plot_idx].grid(alpha=0.3)\n",
    "plot_idx += 1\n",
    "\n",
    "# XGBoost\n",
    "axes[plot_idx].scatter(y_test, xgb_test_pred, alpha=0.5, s=20, color='#2ecc71')\n",
    "axes[plot_idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                   'r--', lw=2)\n",
    "axes[plot_idx].set_xlabel('Actual', fontsize=12)\n",
    "axes[plot_idx].set_ylabel('Predicted', fontsize=12)\n",
    "axes[plot_idx].set_title(f'XGBoost (R¬≤={xgb_test_metrics[\"R2\"]:.3f})', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "axes[plot_idx].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Actual vs Predicted: All Models', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 8: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model comparison\n",
    "comparison_df.to_csv('model_comparison.csv', index=False)\n",
    "print(\"‚úì Model comparison saved: model_comparison.csv\")\n",
    "\n",
    "# Save feature importance\n",
    "rf_importance.to_csv('rf_feature_importance.csv', index=False)\n",
    "xgb_importance.to_csv('xgb_feature_importance.csv', index=False)\n",
    "print(\"‚úì Feature importance saved\")\n",
    "\n",
    "# Save best model predictions (for Vergil!)\n",
    "best_predictions = pd.DataFrame({\n",
    "    'Date': df_clean.loc[test_mask, 'Date'].values,\n",
    "    'City': df_clean.loc[test_mask, 'City'].values,\n",
    "    'Actual_MoM_Change': y_test.values,\n",
    "    'Predicted_MoM_Change': xgb_test_pred if best_model_name == 'XGBoost' else rf_test_pred,\n",
    "    'Error': y_test.values - (xgb_test_pred if best_model_name == 'XGBoost' else rf_test_pred)\n",
    "})\n",
    "\n",
    "best_predictions.to_csv('final_predictions.csv', index=False)\n",
    "print(f\"‚úì Final predictions saved: final_predictions.csv\")\n",
    "print(f\"  (Using {best_model_name})\")\n",
    "\n",
    "print(\"\\n‚úì All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 9: Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä MODELS TESTED:\")\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    star = \" üèÜ\" if row['Model'] == best_model_name else \"\"\n",
    "    print(f\"  {row['Model']:20} - R¬≤: {row['Test_R2']:.4f}, MAPE: {row['Test_MAPE']:.2f}%{star}\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   R¬≤ = {best_r2:.4f} ({best_r2*100:.1f}% variance explained)\")\n",
    "print(f\"   MAPE = {best_mape:.2f}% (average error)\")\n",
    "\n",
    "if best_r2 > 0.85:\n",
    "    print(\"\\n‚úì EXCELLENT performance! (R¬≤ > 0.85)\")\n",
    "elif best_r2 > 0.75:\n",
    "    print(\"\\n‚úì GOOD performance! (R¬≤ > 0.75)\")\n",
    "else:\n",
    "    print(\"\\n‚ö† ACCEPTABLE performance (R¬≤ > 0.70)\")\n",
    "\n",
    "print(\"\\nüìÅ FILES CREATED:\")\n",
    "print(\"  1. model_comparison.csv - Performance metrics for all models\")\n",
    "print(\"  2. rf_feature_importance.csv - Random Forest feature rankings\")\n",
    "print(\"  3. xgb_feature_importance.csv - XGBoost feature rankings\")\n",
    "print(\"  4. final_predictions.csv - Best model predictions (FOR VERGIL!)\")\n",
    "\n",
    "print(\"\\nüì§ NEXT STEPS:\")\n",
    "print(\"  1. Share final_predictions.csv with Vergil (Tableau dashboard)\")\n",
    "print(\"  2. Share model_comparison.csv with Ryan (presentation)\")\n",
    "print(\"  3. Write Milestone 3 report (include all 3 models)\")\n",
    "print(\"  4. Prepare final presentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ADVANCED MODELING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6ef269072ce2486251ca8777149cf0e225657561ea7e50160541b53752ef0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
